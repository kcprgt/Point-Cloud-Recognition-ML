{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6883ac43-34a2-4b74-948b-d439e2ef8e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import laspy\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import seaborn as sns\n",
    "from statistics import fmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92584c22-5668-4d89-ba0f-bbde7700d407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "tf.config.threading.set_inter_op_parallelism_threads(12)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79255d52-ef4f-4fd3-be3c-183bf0650ec7",
   "metadata": {},
   "source": [
    "# Import point cloud data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a93f7ef-e406-4e2b-ab49-d6c22f0c01af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_variance_for_point(i, neighbors, xyz):\n",
    "    indices = neighbors.radius_neighbors(xyz[i:i+1], return_distance=False)[0]\n",
    "    if len(indices) > 1:\n",
    "        return np.var(xyz[indices, 2])\n",
    "    return 0\n",
    "    \n",
    "def load_las_features_labels(file_path, max_samples_per_class):\n",
    "    las = laspy.read(file_path)\n",
    "    \n",
    "    xyz = np.vstack((las.X * las.header.scale[0] + las.header.offset[0],\n",
    "                     las.Y * las.header.scale[1] + las.header.offset[1],\n",
    "                     las.Z * las.header.scale[2] + las.header.offset[2])).T\n",
    "\n",
    "    intensity = las.intensity\n",
    "    classification = las.classification\n",
    "\n",
    "    mask = ~np.isin(classification, [0, 7, 9])\n",
    "    xyz = xyz[mask]\n",
    "    intensity = intensity[mask]\n",
    "    classification = classification[mask]\n",
    "    \n",
    "    \n",
    "    \n",
    "    if hasattr(las, 'red') and hasattr(las, 'green') and hasattr(las, 'blue'):\n",
    "        red = las.red[mask].astype(np.float32) / 65535\n",
    "        green = las.green[mask].astype(np.float32) / 65535\n",
    "        blue = las.blue[mask].astype(np.float32) / 65535\n",
    "    else:\n",
    "        red = np.zeros(len(xyz), dtype=np.float32)\n",
    "        green = np.zeros(len(xyz), dtype=np.float32)\n",
    "        blue = np.zeros(len(xyz), dtype=np.float32)\n",
    "\n",
    "    # Undersampling\n",
    "    if max_samples_per_class:\n",
    "        class_counts = Counter(classification)\n",
    "        selected_indices = []\n",
    "\n",
    "        for cls, count in class_counts.items():\n",
    "            cls_indices = np.where(classification == cls)[0]\n",
    "            if count > max_samples_per_class:\n",
    "                cls_indices = np.random.choice(cls_indices, max_samples_per_class, replace=False)\n",
    "            selected_indices.extend(cls_indices)\n",
    "    \n",
    "        xyz = xyz[selected_indices]\n",
    "        intensity = intensity[selected_indices]\n",
    "        classification = classification[selected_indices]\n",
    "        red = red[selected_indices]\n",
    "        green = green[selected_indices]\n",
    "        blue = blue[selected_indices]\n",
    "    \n",
    "\n",
    "    min_z = np.min(xyz[:, 2])\n",
    "    height_above_ground = xyz[:, 2] - min_z\n",
    "\n",
    "    #neighbors = NearestNeighbors(radius=1, algorithm='kd_tree').fit(xyz)\n",
    "    #local_density = neighbors.radius_neighbors_graph(xyz).sum(axis=1).A1\n",
    "    '''\n",
    "    local_variance = Parallel(n_jobs=12)(\n",
    "        delayed(compute_variance_for_point)(i, neighbors, xyz) for i in range(len(xyz))\n",
    "    )\n",
    "    local_variance = np.array(local_variance, dtype=np.float32)\n",
    "    '''\n",
    "\n",
    "    #One-hot encode labels\n",
    "    le = LabelEncoder()\n",
    "    le.fit(classification)\n",
    "    classification_encoded = le.transform(classification)\n",
    "    class_number = len(le.classes_)\n",
    "    classification_categorical = to_categorical(classification_encoded, class_number)\n",
    "    \n",
    "    features = np.column_stack((intensity, height_above_ground, red, green, blue))\n",
    "\n",
    "    return features, classification_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3e4df0c-8c56-4a6f-ae74-f67f1ac914fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clouds_features(file_paths, max_samples):\n",
    "    max_samples_per_class = int(max_samples / (len(file_paths) - 1))\n",
    "    \n",
    "    clouds = []\n",
    "    for file in file_paths:\n",
    "        features, labels = load_las_features_labels(file, max_samples_per_class)\n",
    "        clouds.append( (features, labels) )\n",
    "    return clouds\n",
    "\n",
    "def merge_features(clouds_features):\n",
    "    features = np.vstack([cloud[0] for cloud in clouds_features])\n",
    "    labels = np.vstack([cloud[1] for cloud in clouds_features])\n",
    "    return features, labels\n",
    "\n",
    "def mean_iou(y_true, y_pred, num_classes):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=np.arange(num_classes))\n",
    "    IoUs = np.diag(cm) / (cm.sum(axis=1) + cm.sum(axis=0) - np.diag(cm) + 1e-7)\n",
    "    return np.nanmean(IoUs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd80ddeb-3347-46e2-b562-a63c98a16304",
   "metadata": {},
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c7a1d4e-8dd1-4b4e-bd30-4e01a25e1b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input((5,)),\n",
    "        tf.keras.layers.Dense(50, activation='relu'),\n",
    "        tf.keras.layers.Dense(50, activation='relu'),\n",
    "        tf.keras.layers.Dense(50, activation='relu'),\n",
    "        tf.keras.layers.Dense(5, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3e15946-369f-4804-a7d6-b37fad86b9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_eval(clouds_features):\n",
    "    acc = []\n",
    "    \n",
    "    for i, cloud in enumerate(clouds_features):\n",
    "        print(f\"Konfiguracja {i}\")\n",
    "        eval_features, eval_labels = cloud \n",
    "        train_clouds = clouds_features[:i] + clouds_features[i+1:] \n",
    "        \n",
    "        train_features, train_labels = merge_features(train_clouds)\n",
    "\n",
    "        #smote = SMOTE(sampling_strategy='auto', random_state=7)\n",
    "        #train_features, train_labels = smote.fit_resample(train_features, train_labels)\n",
    "\n",
    "        model = create_model()\n",
    "        model.fit(train_features, train_labels, epochs=7)\n",
    "        loss, accuracy = model.evaluate(eval_features, eval_labels)\n",
    "        acc.append(accuracy)\n",
    "        \n",
    "        print(f\"Classification Report {i}\")\n",
    "        print(f'accuracy: {accuracy}')\n",
    "  \n",
    "    overal_accuracy = fmean(acc)\n",
    "    print('')\n",
    "    print('Final Raport')\n",
    "    print(f'OA: {overal_accuracy}')\n",
    "    #plot_confusion_matrix(all_eval_labels, all_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b347ab66-56bf-4bfc-9f01-5105ca2bb984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Konfiguracja 0\n",
      "Epoch 1/7\n",
      "\u001b[1m131756/131756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 1ms/step - accuracy: 0.5492 - loss: 1.0375\n",
      "Epoch 2/7\n",
      "\u001b[1m131756/131756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 1ms/step - accuracy: 0.6107 - loss: 0.9042\n",
      "Epoch 3/7\n",
      "\u001b[1m131756/131756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 1ms/step - accuracy: 0.6200 - loss: 0.8813\n",
      "Epoch 4/7\n",
      "\u001b[1m131756/131756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 1ms/step - accuracy: 0.6243 - loss: 0.8697\n",
      "Epoch 5/7\n",
      "\u001b[1m131756/131756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 1ms/step - accuracy: 0.6273 - loss: 0.8618\n",
      "Epoch 6/7\n",
      "\u001b[1m131756/131756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 1ms/step - accuracy: 0.6294 - loss: 0.8564\n",
      "Epoch 7/7\n",
      "\u001b[1m131756/131756\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 1ms/step - accuracy: 0.6309 - loss: 0.8520\n",
      "\u001b[1m37570/37570\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 936us/step - accuracy: 0.2800 - loss: 3.5321\n",
      "Classification Report 0\n",
      "accuracy: 0.4880838096141815\n",
      "Konfiguracja 1\n",
      "Epoch 1/7\n",
      "\u001b[1m130783/130783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 1ms/step - accuracy: 0.5632 - loss: 1.0221\n",
      "Epoch 2/7\n",
      "\u001b[1m122267/130783\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - accuracy: 0.6235 - loss: 0.8837"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m file_paths \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAS/N-34-50-C-d-3-3-2-2.las\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAS/N-34-50-C-d-3-3-2-4.las\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAS/N-34-50-C-c-4-2-2-2.las\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAS/N-34-50-C-c-4-2-2-1.las\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      4\u001b[0m clouds \u001b[38;5;241m=\u001b[39m load_clouds_features(file_paths, \u001b[38;5;241m1000000\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m cross_eval(clouds)\n",
      "Cell \u001b[1;32mIn[37], line 15\u001b[0m, in \u001b[0;36mcross_eval\u001b[1;34m(clouds_features)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#smote = SMOTE(sampling_strategy='auto', random_state=7)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#train_features, train_labels = smote.fit_resample(train_features, train_labels)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m create_model()\n\u001b[1;32m---> 15\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(train_features, train_labels, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m)\n\u001b[0;32m     16\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(eval_features, eval_labels)\n\u001b[0;32m     17\u001b[0m acc\u001b[38;5;241m.\u001b[39mappend(accuracy)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    218\u001b[0m     ):\n\u001b[1;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1689\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1690\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1691\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1692\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1693\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1694\u001b[0m   )\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1703\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Ścieżki do plików LAS\n",
    "file_paths = [\"LAS/N-34-50-C-d-3-3-2-2.las\", \"LAS/N-34-50-C-d-3-3-2-4.las\", \"LAS/N-34-50-C-c-4-2-2-2.las\", \"LAS/N-34-50-C-c-4-2-2-1.las\"]\n",
    "\n",
    "clouds = load_clouds_features(file_paths, 1000000)\n",
    "\n",
    "cross_eval(clouds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
